{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      " 이 크롤러는 RISS 사이트의 논문 및 학술자료 수집용 웹크롤러입니다.\n",
      "====================================================================================================\n",
      "1.수집할 자료의 키워드는 무엇입니까?: 해양자원\n",
      "\n",
      "\n",
      "2. 위 키워드로 아래의 장르 중 어떤 장르의 정보를 수집할까요?\n",
      "\n",
      "1.학위논문       2.국내학술논문     3.해외학술논문     4.학술지      \n",
      "5.단행본         6.공개강의         7.연구보고서     \n",
      "\n",
      "위 장르 중 수집할 장르의 번호를 입력하세요:  2\n",
      "\n",
      "\n",
      "3.결과를 저장할 csv형식의 파일명을 쓰세요(예: c:\\py_temp\\riss_2.csv): c:\\py_temp\\riss_2.csv\n",
      "4.결과를 저장할 xls형식의 파일명을 쓰세요(예: c:\\py_temp\\riss_2.xls): c:\\py_temp\\riss_2.xls\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# riss.kr 에서 특정 키워드로 논문 / 학술 자료 검색하기\n",
    "\n",
    "#Step 1. 필요한 모듈을 로딩합니다\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup     \n",
    "import pandas as pd   \n",
    "import openpyxl\n",
    "import math\n",
    "import time  \n",
    "\n",
    "# Step 2. 크롬 드라이버 설정 \n",
    "s = Service(\"c:/py_temp/chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s)\n",
    "\n",
    "#Step 3. 사용자에게 검색 관련 정보들을 입력 받습니다.\n",
    "print(\"=\" *100)\n",
    "print(\" 이 크롤러는 RISS 사이트의 논문 및 학술자료 수집용 웹크롤러입니다.\")\n",
    "print(\"=\" *100)\n",
    "query_txt = input('1.수집할 자료의 키워드는 무엇입니까?: ')\n",
    "print(\"\\n\")\n",
    "\n",
    "choice = input('''2. 위 키워드로 아래의 장르 중 어떤 장르의 정보를 수집할까요?\n",
    "\n",
    "1.학위논문       2.국내학술논문     3.해외학술논문     4.학술지      \n",
    "5.단행본         6.공개강의         7.연구보고서     \n",
    "\n",
    "위 장르 중 수집할 장르의 번호를 입력하세요:  ''')\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "fc_name = input('3.결과를 저장할 csv형식의 파일명을 쓰세요(예: c:\\\\py_temp\\\\riss_2.csv): ')\n",
    "fx_name = input('4.결과를 저장할 xls형식의 파일명을 쓰세요(예: c:\\\\py_temp\\\\riss_2.xls): ')\n",
    "print(\"\\n\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=103.0.5060.114)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x005D6463+2188387]\n\tOrdinal0 [0x0056E461+1762401]\n\tOrdinal0 [0x00483C40+801856]\n\tOrdinal0 [0x00478932+756018]\n\tOrdinal0 [0x00479168+758120]\n\tOrdinal0 [0x0047AA22+764450]\n\tOrdinal0 [0x00474379+738169]\n\tOrdinal0 [0x004850D0+807120]\n\tOrdinal0 [0x004DC402+1164290]\n\tOrdinal0 [0x004CC5F6+1099254]\n\tOrdinal0 [0x004A6BE0+945120]\n\tOrdinal0 [0x004A7AD6+948950]\n\tGetHandleVerifier [0x008771F2+2712546]\n\tGetHandleVerifier [0x0086886D+2652765]\n\tGetHandleVerifier [0x0066002A+520730]\n\tGetHandleVerifier [0x0065EE06+516086]\n\tOrdinal0 [0x0057468B+1787531]\n\tOrdinal0 [0x00578E88+1805960]\n\tOrdinal0 [0x00578F75+1806197]\n\tOrdinal0 [0x00581DF1+1842673]\n\tBaseThreadInitThunk [0x757CFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77947A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77947A6E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Step 4. 검색어 입력한 후 검색하여 해당 장르로 이동하기\u001b[39;00m\n\u001b[0;32m      2\u001b[0m query_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://www.riss.kr/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m driver\u001b[38;5;241m.\u001b[39mmaximize_window()\n\u001b[0;32m      5\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:442\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m    Loads a web page in the current browser session.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:430\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    428\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 430\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    431\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[0;32m    432\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:247\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    245\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=103.0.5060.114)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x005D6463+2188387]\n\tOrdinal0 [0x0056E461+1762401]\n\tOrdinal0 [0x00483C40+801856]\n\tOrdinal0 [0x00478932+756018]\n\tOrdinal0 [0x00479168+758120]\n\tOrdinal0 [0x0047AA22+764450]\n\tOrdinal0 [0x00474379+738169]\n\tOrdinal0 [0x004850D0+807120]\n\tOrdinal0 [0x004DC402+1164290]\n\tOrdinal0 [0x004CC5F6+1099254]\n\tOrdinal0 [0x004A6BE0+945120]\n\tOrdinal0 [0x004A7AD6+948950]\n\tGetHandleVerifier [0x008771F2+2712546]\n\tGetHandleVerifier [0x0086886D+2652765]\n\tGetHandleVerifier [0x0066002A+520730]\n\tGetHandleVerifier [0x0065EE06+516086]\n\tOrdinal0 [0x0057468B+1787531]\n\tOrdinal0 [0x00578E88+1805960]\n\tOrdinal0 [0x00578F75+1806197]\n\tOrdinal0 [0x00581DF1+1842673]\n\tBaseThreadInitThunk [0x757CFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77947A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77947A6E+238]\n"
     ]
    }
   ],
   "source": [
    "#Step 4. 검색어 입력한 후 검색하여 해당 장르로 이동하기\n",
    "query_url = 'http://www.riss.kr/'\n",
    "driver.get(query_url)\n",
    "time.sleep(10)\n",
    "driver.maximize_window()\n",
    "time.sleep(10)\n",
    "\n",
    "s_time = time.time( )\n",
    "element = driver.find_element(By.ID,'query')\n",
    "driver.find_element(By.ID,'query').click( )\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(\"\\n\")\n",
    "time.sleep(10)\n",
    "\n",
    "# 장르 선택하기\n",
    "if choice == '1' :\n",
    "    driver.find_element(By.LINK_TEXT,'학위논문').click()\n",
    "elif choice =='2':\n",
    "    driver.find_element(By.LINK_TEXT,'국내학술논문').click()\n",
    "elif choice =='3':\n",
    "    driver.find_element(By.LINK_TEXT,'해외학술논문').click()\n",
    "elif choice =='4':\n",
    "    driver.find_element(By.LINK_TEXT,'학술지').click()\n",
    "elif choice =='5':\n",
    "    driver.find_element(By.LINK_TEXT,'단행본').click()\n",
    "elif choice =='6':\n",
    "    driver.find_element(By.LINK_TEXT,'공개강의').click()\n",
    "elif choice =='7':\n",
    "    driver.find_element(By.LINK_TEXT,'연구보고서').click()\n",
    "\n",
    "# Step 5. 크롤링 건수 추출 후 건수 입력받기\n",
    "time.sleep(0.2)\n",
    "html_1 = driver.page_source\n",
    "soup_1 = BeautifulSoup(html_1, 'html.parser')\n",
    "\n",
    "if choice =='1' :\n",
    "    total_1 = soup_1.find('div','searchBox pd')\n",
    "elif choice =='2' :\n",
    "    total_1 = soup_1.find('div','searchBox')\n",
    "elif choice =='3' :\n",
    "    total_1 = soup_1.find('div','searchBox')\n",
    "elif choice =='4' :\n",
    "    total_1 = soup_1.find('div','searchBox pd')\n",
    "elif choice =='5' :\n",
    "    total_1 = soup_1.find('div','searchBox pd')\n",
    "elif choice =='6' :\n",
    "    total_1 = soup_1.find('div','searchBox pd')\n",
    "elif choice =='7' :\n",
    "    total_1 = soup_1.find('div','searchBox pd')\n",
    "\n",
    "total_2 = total_1.select('dl > dd > span')\n",
    "total_3 = total_2[0].find('span','num').get_text()\n",
    "total = total_3.replace(\",\",\"\")\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "#장르 이름 지정하기\n",
    "if choice == '1' :\n",
    "    j_name='학위논문'\n",
    "elif choice =='2':\n",
    "    j_name='국내학술논문'\n",
    "elif choice =='3':\n",
    "    j_name='해외학술논문'\n",
    "elif choice =='4':\n",
    "    j_name='학술지'\n",
    "elif choice =='5':\n",
    "    j_name='단행본'\n",
    "elif choice =='6':\n",
    "    j_name='공개강의'\n",
    "elif choice =='7':\n",
    "    j_name='연구보고서'\n",
    "\n",
    "if total =='0' :\n",
    "    print(\"%s 키워드로 %s 부분에서 검색된 자료의 건수는 총 0건 입니다\" %(query_txt,j_name) )\n",
    "    print(\"검색된 결과 건수가 0건이므로 수집할 데이터가 없어서 종료합니다\")\n",
    "else :\n",
    "    print(\"%s 키워드로 %s 부분에서 검색된 자료의 건수는 총 %s 건 입니다\"%(query_txt,j_name,total))\n",
    "    cnt = int(input('이 중에서 크롤링 할 건수는 몇건입니까?: '))\n",
    "    page_cnt = math.ceil(cnt / 10) \n",
    "\n",
    "    # 국내학술논문 카테고리의 정보 수집하기\n",
    "    if choice =='2' and cnt > 0:\n",
    "        print(\"%s 키워드로 국내학술논문을 검색하여 총 %s 건 중 %s건의 정보를 수집하겠습니다\" %(query_txt,total,cnt))\n",
    "\n",
    "        no2=[]           # 게시글 번호 컬럼\n",
    "        title2=[ ]       # 게시글 제목 컬럼\n",
    "        author2=[]       # 논문 저자 컬럼\n",
    "        company2=[ ]     # 소속 기관 컬럼\n",
    "        date2=[ ]        # 게시글 날짜 컬럼\n",
    "        suksa2=[ ]       # 국내석사 컬럼\n",
    "        contents2=[]     # 초록내용\n",
    "        full_url2=[]     # 논문 원본 URL\n",
    "\n",
    "        no = 1           # 게시글 번호 초기값\n",
    "        k = 0   # 페이지 번호 넘기기 위해 사용하는 변수\n",
    "        #xpath_no = 3\n",
    "\n",
    "        for x in range(1,page_cnt+1) :\n",
    "            print(\"\\n\")\n",
    "            print(\"%s 페이지 내용 수집 시작합니다 =======================\" %x)\n",
    "\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            content_list = soup.find('div','srchResultListW').find_all('li')\n",
    "\n",
    "            for i in content_list:\n",
    "\n",
    "                # 2. 게시글 제목\n",
    "                try:\n",
    "                    title=i.find('div','cont').find('p','title').get_text().strip()\n",
    "                except :\n",
    "                    continue \n",
    "                else :\n",
    "\n",
    "                    # 1.게시글 번호\n",
    "                    print(\"\\n\")\n",
    "                    print(\"%s 번째 정보를 추출하고 있습니다============\" %no)\n",
    "                    no2.append(no)\n",
    "                    print(\"1.번호 : %s\" %no)\n",
    "\n",
    "                    title2.append(title.strip())\n",
    "                    print(\"2.제목 : %s\" %title.strip())\n",
    "\n",
    "                    # 3. 작성자\n",
    "                    try :\n",
    "                        author=i.find('p','etc').find('span','writer').get_text().strip()\n",
    "                    except :\n",
    "                        author = '작성자가 없습니다'\n",
    "                        print(\"3.작성자 : %s\" %author.strip())\n",
    "                        author2.append(author.strip())\n",
    "                    else :\n",
    "                        author2.append(author.strip())\n",
    "                        print(\"3.작성자 : %s\" %author.strip())\n",
    "\n",
    "                    # 4. 소속기관\n",
    "                    try :\n",
    "                        company=i.find('p','etc').find('span','assigned').get_text().strip()\n",
    "                    except :\n",
    "                        company='소속 기관이 없습니다'\n",
    "                        company2.append(company.strip())\n",
    "                        print(\"4.소속기관 : %s\" %company.strip())\n",
    "                    else :\n",
    "                        company2.append(company.strip())\n",
    "                        print(\"4.소속기관 : %s\" %company.strip())\n",
    "\n",
    "                    # 5. 발표날짜\n",
    "                    try :\n",
    "                        date_1 =i.find('p','etc').find_all('span')\n",
    "                        date_2 = date_1[2].get_text().strip()\n",
    "                    except :\n",
    "                        date_2='발표날짜가 없습니다'\n",
    "                        date2.append(date_2)\n",
    "                        print(\"5.발표년도 : %s\" %date_2)\n",
    "                    else :\n",
    "                        date2.append(date_2)\n",
    "                        print(\"5.발표년도 : %s\" %date_2)\n",
    "\n",
    "                    # 6.실린 논문집\n",
    "                    try :\n",
    "                        suksa_1 =i.find('p','etc').find_all('span')\n",
    "                        suksa_2 = suksa_1[3].get_text().strip()\n",
    "                    except :\n",
    "                        suksa_2='논문집이 없습니다'\n",
    "                        suksa2.append(suksa_2)\n",
    "                        print(\"6.논문집/자료집 : %s\" %suksa_2)\n",
    "                    else :\n",
    "                        suksa2.append(suksa_2)\n",
    "                        print(\"6.논문집/자료집 : %s\" %suksa_2)\n",
    "\n",
    "                    # 7.논문 url 주소       \n",
    "                    url_1 = i.find('p','title').find('a')['href']\n",
    "                    full_url = 'http://www.riss.kr'+url_1\n",
    "\n",
    "                    full_url2.append(full_url)\n",
    "                    print('7.논문 URL 주소:' , full_url)\n",
    "\n",
    "                    time.sleep(2)\n",
    "\n",
    "                    #news_no += 1\n",
    "                    no += 1\n",
    "\n",
    "                    if no > cnt :\n",
    "                        break\n",
    "\n",
    "            time.sleep(1)        # 페이지 변경 전 1초 대기 \n",
    "\n",
    "            x += 1\n",
    "\n",
    "            if no >= cnt :\n",
    "                break\n",
    "            \n",
    "        try :\n",
    "            driver.find_element(By.LINK_TEXT,'%s' %x).click() # 다음 페이지번호 클릭\n",
    "        except :\n",
    "            driver.find_element(By.LINK_TEXT,'다음 페이지로').click()\n",
    "\n",
    "# Step 7. 출력 결과 저장하기\n",
    "df = pd.DataFrame()\n",
    "df['번호']=no2\n",
    "df['제목']=pd.Series(title2)\n",
    "df['저자']=pd.Series(author2)\n",
    "df['소속(발행)기관']=pd.Series(company2)\n",
    "df['날짜']=pd.Series(date2)\n",
    "df['학위(논문일경우)']=pd.Series(suksa2)\n",
    "df['초록(논문일경우)']=pd.Series(contents2)\n",
    "df['자료URL주소']=pd.Series(full_url2)\n",
    "\n",
    "# xls / csv 형태로 저장하기\n",
    "df.to_excel(fx_name,index=False, encoding=\"utf-8\",engine='openpyxl')\n",
    "df.to_csv(fc_name,index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "e_time = time.time( )     \n",
    "t_time = e_time - s_time\n",
    "\n",
    "print(\"\\n\") \n",
    "print(\"=\" *80)\n",
    "print(\"크롤링을 요청한 총 %s 건 중에서 %s 건의 데이터를 수집 완료 했습니다\" %(cnt,no-1))\n",
    "print(\"총 소요시간은 %s 초 입니다 \" %round(t_time,1))\n",
    "print(\"=\" *80)\n",
    "\n",
    "driver.close( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
